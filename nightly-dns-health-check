#!/bin/bash

# get today's zone files
# run dns-purist, capturing the essential data
# add today's metrics to the CSV file
#
# RUN FROM CRON - nightly
#

TOPDIR=~tperrine/git-work/dns-purist
DATE=`date +%Y%m%d`
DIR=${TOPDIR}/DNS-data/${DATE}.dnsdata

if [ -d "${DIR}" ]; then
    echo "data directory ${DIR} exists - exit"
    exit 1
fi

LOGFILE=${DIR}/dns-health-check.log

mkdir $DIR

cd ${DIR}

${TOPDIR}/big-zone-xfer > ${LOGFILE}
echo transfer complete
grep failed ${LOGFILE}

# now to run The Big Job

echo starting - `date`

# pass one - just dump all the IPs and names in all the zones, sort -u - this is very fast

time ${TOPDIR}/dns-purist.py --dump_ips *.zone *.revzone | sort -u > dns-ips.$DATE
time ${TOPDIR}/dns-purist.py --dump_names *.zone *.revzone | sort -u > dns-names.$DATE

# pass two - do all the analysis, including using DNS lookups - this is rather slow
time ${TOPDIR}/dns-purist.py --allow_dns_lookups *.zone *.revzone ${TOPDIR}/zone-skip-list.extzone > dns-health.$DATE

#pass three - create the CSV output summary
# horribly inefficient, but provides a good load test and is a hack until I can change the code

time ${TOPDIR}/dns-purist.py --csv_output --allow_dns_lookups *.zone *.revzone ${TOPDIR}/zone-skip-list.extzone
echo ending - `date`

echo "differences between live IPs and DNS IPs"
echo word counts
wc -l ${TOPDIR}/live-ips-latest.sorted dns-ips.$DATE

echo differences
diff ${TOPDIR}/live-ips-latest.sorted dns-ips.$DATE | wc -l

echo "live IPs NOT in DNS"
diff ${TOPDIR}/live-ips-latest.sorted dns-ips.$DATE | grep '<' | wc -l

echo "DNS IPs NOT live at last scan"
diff ${TOPDIR}/live-ips-latest.sorted dns-ips.$DATE | grep '>' | wc -l



